---
title: "CRPD Stream 1"
author: "Theodore Ochieng"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r Load Packages}
library(tidyverse)# Also loads dplyr, ggplot2, and haven
```


# Part 1: Load Data
```{r Load Data}
CRPD_StateReports <- read_csv("CRPD_Data/CRPD_StateReports_English.csv")
combined_stopwords <- read_csv("CRPD_Data/combined_stopwords.csv")

head(CRPD_StateReports)
head(combined_stopwords)
```


```{r Records by Grouping}
# ---- Year ----
CRPD_StateReports %>% 
  count(Year) %>% 
  mutate(prop = round(n/sum(n), 4)) %>% 
  arrange(desc(Year))

# ---- Session ----
CRPD_StateReports %>% 
  count(Session, sort = T) %>% 
  mutate(prop = round(n/sum(n), 4))

# ---- Country ----
CRPD_StateReports %>% 
  count(Country, sort = T) %>% 
  mutate(prop = round(n/sum(n), 4))
```


# Part 2: Keyword and Key-phrase Analysis
## Keywords
```{r Create Unigrams}
CRPD_StateReports_words <- 
  CRPD_StateReports %>%
  unnest_tokens(word, text) %>% 
  anti_join(combined_stopwords, by = "word")

tibble(CRPD_StateReports_words) %>%
  count(word, sort = T)

# Write to CSV
# tibble(CRPD_StateReports_words) %>%
#   count(word, sort = T) %>%
#   write_csv("CRPD_Meta/Metadata/unigram_counts_v2.csv")
```


```{r Plot - Frequent Words}
CRPD_StateReports_words %>%
  count(word, sort = TRUE) %>%
  top_n(25) %>% 
  mutate(word=reorder(word, n)) %>%
  ggplot(aes(word,n)) +geom_col() + xlab(NULL) + ylab("Frequency") + coord_flip() +
  geom_col(fill = "light blue")
```


```{r TF-IDF Unigram}
unigram_tf_idf <- CRPD_StateReports_words %>%
  count(doc_id, word) %>% 
  bind_tf_idf(word, doc_id, n) %>%
  arrange(desc(tf_idf)) %>% 
  as_tibble()

unigram_tf_idf

unigram_tf_idf %>% 
  top_n(25) %>% 
  ggplot(aes(reorder(word,tf_idf),tf_idf)) +geom_col() + coord_flip() + 
  geom_col(fill = "light blue") +
  labs(x = "")

# Write CSV
# unigram_tf_idf %>%
#   write_csv("CRPD_Meta/Metadata/unigram_tf_idf.csv")
```


## Key Phrases
### Bigram
```{r Create Bigrams}
CRPD_StateReports_bigrams <- CRPD_StateReports %>%
  unnest_tokens(bigram, text, token = "ngrams", n=2)

CRPD_StateReports_bigrams %>%
  count(bigram, sort = TRUE) %>% 
  tibble() %>% 
  head(100)
```


```{r Bigrams Separated and Filtered}
# Runtime: 2mins
bigrams_filtered <- CRPD_StateReports_bigrams %>%
  filter(!grepl('[0-9]', bigram)) %>%
  separate(bigram, c("word1", "word2"), sep = " ") %>% 
  as_tibble() %>% 
  filter(!word1 %in% combined_stopwords$word) %>%
  filter(!word2 %in% combined_stopwords$word)

bigrams_filtered
```


```{r Bigrams Unite}
bigram_counts <- bigrams_filtered %>%
  count(word1, word2, sort = TRUE)

bigram_counts

bigrams_united <- bigrams_filtered %>%
  unite(bigram, word1, word2, sep = " ")

bigrams_united %>%
  as_tibble() %>% 
  count(bigram, sort = T)

# Write to CSV
# bigram_counts %>% 
#   write_csv("CRPD_Meta/Metadata/bigram_counts.csv")
```


```{r Plot - Bigram Frequency}
bigrams_united %>%
  count(bigram, sort = TRUE) %>% 
  mutate(bigram=reorder(bigram, n)) %>% 
  top_n(25) %>% 
  ggplot(aes(bigram,n)) +geom_col() + xlab(NULL) + ylab("Frequency") + coord_flip() +
  geom_col(fill = "light blue") +
  labs(title='Frequently Used Phrases (Bigrams)')
```


```{r Check Word Precedents and Dependents}
bigrams_filtered %>%
  filter(word1 == "world") %>%
  count(word1, word2, sort = TRUE)

bigrams_filtered %>%
  filter(word2 == "bank") %>%
  count(word1, word2, sort = TRUE)
```


```{r TF-IDF Bigram}
bigram_tf_idf <- bigrams_united %>%
  count(doc_id, bigram) %>%
  bind_tf_idf(bigram, doc_id, n) %>%
  arrange(desc(tf_idf))

bigram_tf_idf

bigram_tf_idf %>%
  top_n(25) %>% 
  ggplot(aes(reorder(bigram,tf_idf),tf_idf)) +geom_col() + coord_flip() + 
  geom_col(fill = "light blue") +
  labs(x = " ", title='Bigrams: TF-IDF')

# Write CSV
# bigram_tf_idf %>%
#   write_csv("CRPD_Meta/Metadata/bigram_tf_idf.csv")
```


### Trigram
```{r Create Trigrams}
CRPD_StateReports_trigrams <- CRPD_StateReports %>%
  unnest_tokens(trigram, text, token = "ngrams", n=3)

CRPD_StateReports_trigrams %>%
  count(trigram, sort = TRUE) %>% 
  tibble() %>% 
  head(100)
```


```{r Trigrams Separated and Filtered}
# Runtime: 2m14s
trigrams_filtered <- CRPD_StateReports_trigrams %>%
  filter(!grepl('[0-9]', trigram)) %>%
  separate(trigram, c("word1", "word2", "word3"), sep = " ") %>% 
  as_tibble() %>% 
  filter(!word1 %in% combined_stopwords$word) %>%
  filter(!word2 %in% combined_stopwords$word) %>% 
  filter(!word3 %in% combined_stopwords$word)

trigrams_filtered
```


```{r Trigrams Unite}
trigram_counts <- trigrams_filtered %>%
  count(word1, word2, word3, sort = TRUE)

trigram_counts

trigrams_united <- trigrams_filtered %>%
  unite(trigram, word1, word2, word3, sep = " ")

trigrams_united %>%
  as_tibble() %>% 
  count(trigram, sort = T)

# Write to CSV
# trigram_counts %>%
#   write_csv("CRPD_Meta/Metadata/trigram_counts.csv")
```


```{r Plot - Trigram Frequency}
trigrams_united %>%
  count(trigram, sort = TRUE) %>% 
  mutate(trigram=reorder(trigram, n)) %>% 
  top_n(25) %>% 
  ggplot(aes(trigram,n)) +geom_col() + xlab(NULL) + ylab("Frequency") + coord_flip() +
  geom_col(fill = "light blue") +
  labs(title='Frequently Used Phrases (trigrams)')
```


```{r Check Word Precedents and Dependents}
trigrams_filtered %>%
  filter(word1 == "world") %>%
  count(word1, word2, sort = TRUE)

trigrams_filtered %>%
  filter(word2 == "bank") %>%
  count(word1, word2, sort = TRUE)

trigrams_filtered %>%
  filter(word3 == "bank") %>%
  count(word1, word2, sort = TRUE)
```


```{r TF-IDF Trigram}
trigram_tf_idf <- trigrams_united %>%
  count(doc_id, trigram) %>%
  bind_tf_idf(trigram, doc_id, n) %>%
  arrange(desc(tf_idf))

trigram_tf_idf

trigram_tf_idf %>%
  top_n(25) %>% 
  ggplot(aes(reorder(trigram,tf_idf),tf_idf)) +geom_col() + coord_flip() + 
  geom_col(fill = "light blue") +
  labs(x = " ", title='Trigrams: TF-IDF')

# Write CSV
# trigram_tf_idf %>%
#   write_csv("CRPD_Meta/Metadata/trigram_tf_idf.csv")
```


# Part 3: Dictionary Analysis
## CRPD Full Dictionary
```{r Load Packages}
library(quanteda)
```

```{r Import Dictionary}
dict_CRPD <- readRDS("CRPD_Data/Dictionary/dict_CRPDFull.rds")
```


### Data Prep
```{r Create Corpus}
mycorpus <- corpus(CRPD_StateReports)

# corpus statistics for the first 10 observations
summary(mycorpus, 10)
```


```{r Create Tokens}
mytoken <-
  tokens(
    mycorpus,
    remove_numbers = TRUE,
    remove_punct = TRUE,
    remove_symbols = TRUE,
    remove_url = TRUE,
    split_hyphens = TRUE,
    include_docvars = TRUE
  )

mytoken<-tokens_tolower(mytoken)
mytoken<-tokens_remove(mytoken,combined_stopwords$word)

head(mytoken)
```


```{r Create DFM}
# Create Document-Feature Matrix (DFM)

# Without stemming
mydfm <- dfm(mytoken)
```


### Apply Dictionary
```{r Full Dictionary}
# dictionary with 1 level (category)
df.dictApplied_Category <- mytoken %>% 
  tokens_lookup(dictionary = dict_CRPD,
                valuetype = "glob",
                levels = 1) %>% 
  dfm() %>%
  convert(to = "data.frame")

head(df.dictApplied_Category)

# dictionary with 2 levels (category and subcategory)
df.dictApplied_CatSubcategory <- mytoken %>% 
  tokens_lookup(dictionary = dict_CRPD,
                valuetype = "glob",
                levels = 1:2) %>% 
  dfm() %>%
  convert(to = "data.frame")

head(df.dictApplied_CatSubcategory)
```


```{r Full Dictionary - Visualization, fig.height=2.5}
# Category Plot
df.dictApplied_Category %>% 
  select(-doc_id) %>% 
  pivot_longer(everything(), names_to = "Category", values_to = "count") %>% # transpose columns to rows
  plyr::ddply("Category", plyr::colwise(sum)) %>% # aggregate counts by category
  arrange(count) %>%
  ggplot(aes(x=reorder(toupper(Category), count), 
             y=count)) +
  geom_bar(stat='identity') +
  coord_flip()


# Category-Subcategory Plot
df.dictApplied_CatSubcategory %>% 
  select(-doc_id) %>% 
  pivot_longer(everything(), names_to = "CatSubcategory", values_to = "count") %>% # transpose columns to rows
  plyr::ddply("CatSubcategory", plyr::colwise(sum)) %>% # aggregate counts by category
  arrange(count) %>%
  top_n(25) %>% 
  ggplot(aes(x=reorder(toupper(CatSubcategory), count), 
             y=count)) +
  geom_bar(stat='identity') +
  coord_flip()
```


```{r Article 33}
df.dictApplied_Article33 <- mytoken %>% 
  tokens_lookup(dictionary = dict_CRPD$Article_33,
                valuetype = "glob",
                levels = 1) %>% 
  dfm() %>%
  convert(to = "data.frame")

head(df.dictApplied_Article33)

# Category-Subcategory Plot
df.dictApplied_Article33 %>% 
  select(-doc_id) %>% 
  pivot_longer(everything(), names_to = "CatSubcategory", values_to = "count") %>% # transpose columns to rows
  plyr::ddply("CatSubcategory", plyr::colwise(sum)) %>% # aggregate counts by category
  arrange(count) %>%
  top_n(25) %>% 
  ggplot(aes(x=reorder(toupper(CatSubcategory), count), 
             y=count)) +
  geom_bar(stat='identity') +
  coord_flip()
```


### Keyword-In-Context (KWIC)
Use this section to investigate words driving dictionary categorization.
```{r KWIC by Category}
# see keywords-in-context for dictionary entries

# search by words in category
kwic(mytoken, pattern = phrase(dict_CRPD$Article_15)) %>% 
  head(100)

# search by words in subcategory
kwic(mytoken, pattern = phrase(dict_CRPD$Article_14$Paragraph_2)) %>% 
  head(100)
```


```{r KWIC by Word}
# search by specific word
kwic(mytoken, pattern = phrase("respect")) %>% 
  head(100)
```




